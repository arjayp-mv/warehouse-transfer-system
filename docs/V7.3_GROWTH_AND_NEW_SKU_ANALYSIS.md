# V7.3 Enhancement Analysis: Growth Rate & New SKU Forecasting

**Purpose:** Technical analysis of current forecasting methodology vs. proposed improvements for expert validation.

**Date:** 2025-10-19
**Current Version:** V7.2.4
**Proposed Version:** V7.3

---

## PART 1: GROWTH RATE METHODOLOGY

### Current Implementation (V7.2.4)

**Location:** `backend/forecasting.py` lines 49-58

**How It Works:**
```python
class ForecastEngine:
    def __init__(self, forecast_run_id: int, growth_rate: float = 0.0):
        self.forecast_run_id = forecast_run_id
        self.growth_rate = growth_rate  # Single rate for ALL SKUs
```

**Current Process:**
1. User manually enters growth rate when generating forecast (e.g., 0.05 for 5%)
2. This SAME rate is applied uniformly to ALL SKUs in the forecast
3. Growth rate is applied in `_calculate_monthly_forecasts()` at line 268-289:
   ```python
   for month_offset in range(12):
       # Base forecast with seasonal adjustment
       forecast_qty = base_demand * seasonal_factor

       # Apply uniform growth rate (if provided)
       if self.growth_rate > 0:
           growth_multiplier = (1 + self.growth_rate) ** (month_offset / 12.0)
           forecast_qty *= growth_multiplier
   ```

**Current Limitations:**
- **One-size-fits-all:** A battery growing 20% and a cable declining 10% both get same rate
- **Manual guesswork:** User must estimate average growth for entire catalog
- **No SKU-specific trends:** Ignores actual historical performance patterns
- **Example Problem:**
  - User sets 5% growth for all SKUs
  - UB-YTX14-BS is declining 15% (actual trend from data)
  - System forecasts 5% growth instead of 15% decline
  - Result: Over-forecasting, excess inventory

**Current Data Available (Not Used):**
```sql
-- We have this historical data but don't analyze it for trends:
SELECT year_month, corrected_demand_burnaby
FROM monthly_sales
WHERE sku_id = 'UB-YTX14-BS'
ORDER BY year_month DESC
LIMIT 12;

-- Example actual data:
-- 2025-09: 693 units
-- 2025-08: 806 units
-- 2025-07: 887 units
-- 2025-06: 974 units
-- 2025-05: 979 units
-- 2025-04: 1105 units
-- Clear declining trend: -37% over 6 months
```

---

### Proposed Implementation (V7.3)

**Goal:** Calculate growth rate per SKU based on historical trend, with optional manual override.

**New Function:** `calculate_sku_growth_rate(sku_id, warehouse, lookback_months=12)`

**Algorithm: Simple Linear Regression**
```python
def calculate_sku_growth_rate(self, sku_id: str, warehouse: str, lookback_months: int = 12) -> float:
    """
    Calculate annualized growth rate from historical sales trend.

    Uses simple linear regression: y = mx + b
    Where m (slope) indicates trend direction and magnitude.

    Returns:
        float: Annualized growth rate (e.g., 0.15 for 15% growth, -0.10 for 10% decline)
    """
    # Get historical monthly sales (most recent first)
    query = """
        SELECT `year_month`, {demand_column} as demand
        FROM monthly_sales
        WHERE sku_id = %s
          AND {demand_column} > 0
        ORDER BY `year_month` DESC
        LIMIT %s
    """

    results = execute_query(query, (sku_id, lookback_months))

    if len(results) < 3:
        # Insufficient data for trend analysis
        return 0.0

    # Reverse to chronological order for regression
    results.reverse()

    # Prepare data: months as sequential numbers, sales as y-values
    months = list(range(len(results)))  # [0, 1, 2, ..., n]
    sales = [float(row['demand']) for row in results]

    # Calculate linear regression slope using least squares method
    n = len(months)
    sum_x = sum(months)
    sum_y = sum(sales)
    sum_xy = sum(x * y for x, y in zip(months, sales))
    sum_x2 = sum(x * x for x in months)

    # Slope formula: m = (n*Σxy - Σx*Σy) / (n*Σx² - (Σx)²)
    slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)

    # Convert slope to annualized growth rate
    avg_sales = sum_y / n
    if avg_sales == 0:
        return 0.0

    # Monthly trend rate
    monthly_rate = slope / avg_sales

    # Annualized growth rate (compound over 12 months)
    annualized_rate = monthly_rate * 12

    # Cap extreme values for safety
    annualized_rate = max(-0.50, min(0.50, annualized_rate))  # Cap at ±50%

    return annualized_rate
```

**Example Calculation with Real Data (UB-YTX14-BS):**
```
Historical Data (6 months):
Month 0 (Apr): 1105 units
Month 1 (May): 979 units
Month 2 (Jun): 974 units
Month 3 (Jul): 887 units
Month 4 (Aug): 806 units
Month 5 (Sep): 693 units

Linear Regression:
- Slope (m) = -82.4 units/month
- Average sales = 907 units
- Monthly decline rate = -82.4 / 907 = -0.091 (9.1% per month)
- Annualized rate = -0.091 * 12 = -1.09 → Capped at -0.50 (50% decline max)

Result: growth_rate = -0.37 (37% annual decline)
This matches actual 6-month decline: (693-1105)/1105 = -37%
```

**Integration Points:**

1. **Modify `ForecastEngine.__init__()`:**
```python
def __init__(self, forecast_run_id: int, manual_growth_override: Optional[float] = None):
    self.forecast_run_id = forecast_run_id
    self.manual_growth_override = manual_growth_override  # None = auto-calculate
```

2. **Modify `generate_forecast_for_sku()`:**
```python
def generate_forecast_for_sku(self, sku_id: str, warehouse: str = 'combined') -> Dict:
    # Get SKU info and base demand (existing)
    sku_info = self._get_sku_info(sku_id)
    base_demand = self._get_base_demand(sku_id, warehouse, sku_info)

    # NEW: Calculate growth rate per SKU
    if self.manual_growth_override is not None:
        # User provided manual override - use it for all SKUs
        growth_rate = self.manual_growth_override
        growth_source = 'manual_override'
    else:
        # Auto-calculate from historical trend
        growth_rate = self.calculate_sku_growth_rate(sku_id, warehouse)
        growth_source = 'calculated_trend'

    # Store in metadata for transparency
    metadata = {
        'growth_rate_applied': growth_rate,
        'growth_rate_source': growth_source
    }

    # Continue with forecast calculation...
```

3. **Database Storage:**
```sql
-- forecast_details table already has:
-- growth_rate_applied DECIMAL(5,4) DEFAULT 0.0000

-- Add new column for transparency:
ALTER TABLE forecast_details
ADD COLUMN growth_rate_source ENUM('manual_override', 'calculated_trend', 'default')
DEFAULT 'default';
```

**User Workflow:**
- **Scenario A:** User leaves growth rate blank
  - Each SKU analyzed independently
  - UB-YTX14-BS gets -37% growth (declining)
  - UB-YTX7A-BS gets +15% growth (growing)

- **Scenario B:** User enters 0.05 (5%)
  - All SKUs get 5% growth uniformly (current behavior preserved)

- **Scenario C:** Mixed approach (future enhancement)
  - User could apply calculated growth only to Class A SKUs
  - Manual growth for Class C SKUs

---

## PART 2: NEW SKU FORECASTING

### Current Implementation (V7.2.4)

**Location:** `backend/forecasting.py` lines 129-206

**How It Works:**

1. **Base Demand Calculation** (`_get_base_demand()`):
```python
def _get_base_demand(self, sku_id: str, warehouse: str, sku_info: Dict) -> float:
    # Get ABC/XYZ classification
    classification = f"{sku_info['abc_code']}{sku_info['xyz_code']}"
    method_config = self.METHOD_CONFIG.get(classification)

    # Example: BZ classification uses Simple MA with 3 months
    # method_config = {'method': 'simple', 'months': 3, 'confidence': 0.55}

    # Query for historical data
    query = """
        SELECT {demand_column} as total_demand
        FROM monthly_sales
        WHERE sku_id = %s
          AND `year_month` >= %s
          AND {demand_column} > 0
        ORDER BY `year_month` DESC
        LIMIT %s  -- Limit = 3 for BZ classification
    """

    results = execute_query(query, (sku_id, cutoff_date, 3))

    if not results:
        # Fallback to sku_demand_stats
        return self._get_demand_from_stats(sku_id, warehouse)

    demands = [float(row['total_demand']) for row in results]

    # Calculate simple average
    return statistics.mean(demands)  # e.g., (50 + 60 + 55) / 3 = 55
```

2. **Example: UB-YTX7A-BS (B-Z Classification)**

**Actual Data:**
```sql
SELECT year_month, burnaby_sales, corrected_demand_burnaby
FROM monthly_sales
WHERE sku_id = 'UB-YTX7A-BS'
ORDER BY year_month DESC;

-- Result: Only 2-3 months of data available
-- 2025-09: 45 units
-- 2025-08: 52 units
-- 2025-07: 38 units
-- Average: 45 units/month
```

**Current Forecast Logic:**
```python
# BZ classification: Simple MA, 3 months
base_demand = (45 + 52 + 38) / 3 = 45 units/month

# Apply seasonal factors (let's say October factor = 1.2)
october_forecast = 45 * 1.2 = 54 units

# Apply manual growth rate (user set 0% for safety)
october_forecast = 54 * (1 + 0.0) = 54 units

# 12-month forecast: ~54-60 units/month depending on seasonality
```

**Current Limitations:**
1. **No data scarcity detection:** System doesn't know this is a new SKU
2. **No safety buffer:** Treats new SKU same as established SKU with 12+ months data
3. **No similar SKU analysis:** Doesn't look at comparable products
4. **Confidence score misleading:** Shows 0.55 confidence even with only 2 months data
5. **Result:** Under-forecasting → Stockout risk

**Real-World Impact:**
- Forecast: 54 units/month
- Actual demand: Could be 80-100 units (growth phase)
- Stockout → Lost sales → Customer dissatisfaction

---

### Proposed Implementation (V7.3)

**Goal:** Multi-technique approach for SKUs with limited historical data (< 6 months).

**New Function:** `_handle_limited_data_sku()`

```python
def _handle_limited_data_sku(
    self,
    sku_id: str,
    warehouse: str,
    sku_info: Dict,
    available_months: int
) -> Tuple[float, Dict]:
    """
    Handle forecasting for SKUs with limited historical data using combination approach.

    Techniques:
    1. Use available data (even if < 3 months)
    2. Find similar SKUs for demand comparison
    3. Apply safety multiplier based on data scarcity
    4. Boost growth rate for new product adoption curve

    Args:
        sku_id: SKU identifier
        warehouse: Warehouse location
        sku_info: SKU information (category, ABC/XYZ, etc.)
        available_months: Number of months of data available

    Returns:
        Tuple[float, Dict]: (adjusted_base_demand, metadata)
    """
    metadata = {
        'data_quality': 'new_sku' if available_months < 3 else 'limited',
        'available_months': available_months,
        'similar_skus_used': [],
        'safety_multiplier': 1.0,
        'technique': []
    }

    # STEP 1: Calculate base from available data (even if < 3 months)
    query = """
        SELECT {demand_column} as demand
        FROM monthly_sales
        WHERE sku_id = %s AND {demand_column} > 0
        ORDER BY `year_month` DESC
        LIMIT %s
    """
    results = execute_query(query, (sku_id, available_months))

    if results:
        actual_demands = [float(row['demand']) for row in results]
        base_from_actual = statistics.mean(actual_demands)
        metadata['technique'].append('actual_data')
    else:
        base_from_actual = 0.0

    # STEP 2: Find similar SKUs for comparison
    similar_skus = self._find_similar_skus(sku_id, sku_info, warehouse)

    if similar_skus:
        # Get average demand from similar SKUs
        similar_demands = []
        for similar_sku_id in similar_skus[:5]:  # Top 5 most similar
            similar_demand = self._get_base_demand(similar_sku_id, warehouse, sku_info)
            if similar_demand > 0:
                similar_demands.append(similar_demand)
                metadata['similar_skus_used'].append(similar_sku_id)

        if similar_demands:
            base_from_similar = statistics.mean(similar_demands)
            metadata['technique'].append('similar_sku_average')
        else:
            base_from_similar = 0.0
    else:
        base_from_similar = 0.0

    # STEP 3: Combine actual and similar SKU data
    if base_from_actual > 0 and base_from_similar > 0:
        # Weight toward actual data if available
        weight_actual = min(0.5 + (available_months * 0.1), 0.8)  # 50-80% weight
        weight_similar = 1.0 - weight_actual

        base_demand = (base_from_actual * weight_actual) +
                      (base_from_similar * weight_similar)
        metadata['technique'].append('weighted_combination')
    elif base_from_actual > 0:
        base_demand = base_from_actual
    elif base_from_similar > 0:
        base_demand = base_from_similar
    else:
        # Last resort: use category average
        base_demand = self._get_category_average(sku_info['category'], warehouse)
        metadata['technique'].append('category_average')

    # STEP 4: Apply safety multiplier based on data scarcity
    if available_months < 3:
        safety_multiplier = 1.5  # Very new SKU: 50% buffer
        metadata['data_quality'] = 'new_sku'
    elif available_months < 6:
        safety_multiplier = 1.3  # Limited data: 30% buffer
        metadata['data_quality'] = 'limited'
    else:
        safety_multiplier = 1.0  # Sufficient data
        metadata['data_quality'] = 'sufficient'

    metadata['safety_multiplier'] = safety_multiplier
    adjusted_base_demand = base_demand * safety_multiplier

    return adjusted_base_demand, metadata
```

**Supporting Function: Find Similar SKUs**

```python
def _find_similar_skus(self, sku_id: str, sku_info: Dict, warehouse: str) -> List[str]:
    """
    Find SKUs similar to the given SKU for demand comparison.

    Similarity criteria (in priority order):
    1. Same category + same ABC/XYZ classification
    2. Same category + similar ABC classification (A with A, B with B)
    3. Same ABC/XYZ classification only

    Returns:
        List of similar SKU IDs (max 10)
    """
    query = """
        SELECT s.sku_id
        FROM skus s
        INNER JOIN sku_demand_stats sds
            ON s.sku_id = sds.sku_id AND sds.warehouse = %s
        WHERE s.sku_id != %s
          AND s.status = 'active'
          AND sds.demand_6mo_weighted > 0
          AND (
              -- Priority 1: Same category + classification
              (s.category = %s AND s.abc_code = %s AND s.xyz_code = %s)
              OR
              -- Priority 2: Same category + similar ABC
              (s.category = %s AND s.abc_code = %s)
              OR
              -- Priority 3: Same classification
              (s.abc_code = %s AND s.xyz_code = %s)
          )
        ORDER BY
            CASE
                WHEN s.category = %s AND s.abc_code = %s AND s.xyz_code = %s THEN 1
                WHEN s.category = %s AND s.abc_code = %s THEN 2
                ELSE 3
            END,
            sds.demand_6mo_weighted DESC
        LIMIT 10
    """

    params = (
        warehouse, sku_id,
        sku_info['category'], sku_info['abc_code'], sku_info['xyz_code'],  # Priority 1
        sku_info['category'], sku_info['abc_code'],  # Priority 2
        sku_info['abc_code'], sku_info['xyz_code'],  # Priority 3
        sku_info['category'], sku_info['abc_code'], sku_info['xyz_code'],  # ORDER BY 1
        sku_info['category'], sku_info['abc_code']  # ORDER BY 2
    )

    results = execute_query(query, params, fetch_all=True)
    return [row['sku_id'] for row in results]
```

**Example: UB-YTX7A-BS with New Logic**

```python
# Input Data:
sku_id = 'UB-YTX7A-BS'
available_months = 3
actual_data = [38, 52, 45]  # Jul, Aug, Sep 2025

# STEP 1: Base from actual data
base_from_actual = (38 + 52 + 45) / 3 = 45 units

# STEP 2: Find similar SKUs
similar_skus = [
    'UB-YTX14-BS',  # Same category (batteries), same B classification
    'UB-YTX20L-BS',  # Same category, different size
    'UB-YTX9-BS'     # Same category, similar demand pattern
]

# Get their average demand
similar_demands = [887, 1250, 320]  # From their 12-month history
base_from_similar = (887 + 1250 + 320) / 3 = 819 units

# STEP 3: Weighted combination
# Only 3 months actual data → 60% weight to actual, 40% to similar
weight_actual = 0.5 + (3 * 0.1) = 0.8  # Capped at 80%
weight_similar = 0.2

base_demand = (45 * 0.8) + (819 * 0.2) = 36 + 164 = 200 units

# STEP 4: Apply safety multiplier
# 3 months data → Limited category → 1.3x multiplier
adjusted_base_demand = 200 * 1.3 = 260 units/month

# STEP 5: Growth rate boost (from Part 1)
# New SKU → Minimum 10% growth assumption
growth_rate = max(calculated_trend, 0.10) = 0.10

# Final October Forecast:
# October seasonal factor = 1.2
october_forecast = 260 * 1.2 * (1 + 0.10)^(1/12) = 260 * 1.2 * 1.008 = 315 units

# Comparison:
# OLD METHOD: 54 units/month
# NEW METHOD: 260-315 units/month (4.8x-5.8x higher)
# SAFETY BUFFER: 4.8x reduces stockout risk significantly
```

**Metadata Storage:**

```sql
-- forecast_details table enhancements:
ALTER TABLE forecast_details
ADD COLUMN data_quality ENUM('sufficient', 'limited', 'new_sku') DEFAULT 'sufficient',
ADD COLUMN similar_skus_used JSON DEFAULT NULL,
ADD COLUMN safety_multiplier DECIMAL(3,2) DEFAULT 1.00,
ADD COLUMN forecasting_technique VARCHAR(255) DEFAULT NULL;

-- Example stored data:
{
    "sku_id": "UB-YTX7A-BS",
    "data_quality": "limited",
    "available_months": 3,
    "similar_skus_used": ["UB-YTX14-BS", "UB-YTX20L-BS", "UB-YTX9-BS"],
    "safety_multiplier": 1.30,
    "forecasting_technique": "actual_data,similar_sku_average,weighted_combination",
    "base_demand_used": 260,
    "growth_rate_applied": 0.10,
    "growth_rate_source": "new_sku_boost"
}
```

---

## VALIDATION QUESTIONS FOR FORECASTING EXPERT

### Growth Rate Methodology:

1. **Is linear regression appropriate for sales trend analysis?**
   - Should we use exponential smoothing instead?
   - Should we weight recent months more heavily in regression?

2. **Is ±50% cap on growth rate reasonable?**
   - Too conservative or too aggressive?
   - Should cap vary by ABC/XYZ classification?

3. **Should we use polynomial regression for non-linear trends?**
   - Detect acceleration/deceleration in growth?

4. **Minimum data points:**
   - Is 3 months sufficient for trend analysis?
   - Should we require 6+ months for auto-calculation?

### New SKU Methodology:

5. **Is 1.5x safety multiplier appropriate for new SKUs?**
   - Industry standard?
   - Should vary by product category?

6. **Similar SKU matching logic:**
   - Is category + ABC/XYZ the right similarity criteria?
   - Should we include price point, supplier, or other factors?

7. **Weighting between actual vs similar SKU data:**
   - Is 60-80% weight on actual data reasonable?
   - Should weight increase linearly with available months?

8. **Growth rate boost for new SKUs:**
   - Is minimum 10% growth assumption valid?
   - Should it vary based on product lifecycle (intro vs growth phase)?

9. **Data quality thresholds:**
   - < 3 months = "New SKU" (1.5x multiplier)
   - 3-6 months = "Limited Data" (1.3x multiplier)
   - 6+ months = "Sufficient" (1.0x multiplier)
   - Are these thresholds appropriate?

10. **Stockout prevention:**
    - Will 1.3-1.5x multiplier sufficiently reduce stockout risk?
    - Should we combine with service level targets (e.g., 95% fill rate)?

---

## BUSINESS CONTEXT

**Industry:** Automotive parts distribution (batteries, cables, accessories)

**SKU Characteristics:**
- 2000-4000 SKUs total
- High variability (XYZ classification)
- Seasonal patterns (winter demand for batteries)
- New products introduced regularly
- Some SKUs in decline phase

**Consequences:**
- **Under-forecasting:** Stockout → Lost sales → Customer goes to competitor
- **Over-forecasting:** Excess inventory → Cash tied up → Obsolescence risk

**Current Pain Points:**
- New SKUs frequently stock out (UB-YTX7A-BS example)
- Manual growth rate guessing is inaccurate
- No systematic approach for data-scarce SKUs

**Success Metrics:**
- Reduce new SKU stockout rate by 50%
- Improve forecast accuracy (MAPE) by 15-20%
- Reduce manual adjustment effort by 30%

---

## TECHNICAL CONSTRAINTS

**Database:** MySQL 10.4.32-MariaDB
**Backend:** Python 3.x with FastAPI
**No external dependencies:** Cannot use scikit-learn or pandas (keeping it lightweight)
**Performance:** Must handle 4000 SKUs in < 5 minutes
**Data availability:** 24 months of historical sales data maximum

---

## SUMMARY

**Current State:**
- Growth rate: Manual, uniform across all SKUs
- New SKUs: Treated same as established SKUs, no safety buffer

**Proposed State:**
- Growth rate: Auto-calculated per SKU via linear regression, optional manual override
- New SKUs: Multi-technique approach with safety multipliers and similar SKU analysis

**Expected Improvement:**
- UB-YTX7A-BS forecast: 54 → 260-315 units/month (4.8-5.8x increase)
- SKU-specific growth rates capture actual trends (growth vs decline)
- Reduced stockout risk for new products

**Request:** Please validate these methodologies from forecasting best practices perspective.
